# SCENEbench
This repository accompanies SCENEBench, a benchmark suite for evaluating audio understanding in Large Audio Language Models (LALMs) beyond automatic speech recognition. SCENEBench targets real-world audio comprehension across background sound understanding, noise localization, cross-linguistic speech understanding, and vocal characterizer recognition, and includes both synthetic and human-recorded validation data to support ecological validity.

The code and benchmark materials are currently being prepared for public release after the preprint of the paper. We are finalizing documentation, dataset packaging, and evaluation scripts to ensure clarity, reproducibility, and responsible use.

Initial version of the dataset is available at: https://osf.io/dwnmh/overview?view_only=1fecb24539aa44f19dfddebc5b5b9362

If you would like access to the benchmark or evaluation code prior to the public release, please contact laya [at] stanford.edu.
